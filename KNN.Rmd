---
title: "K-NN"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(class)
library(MLmetrics)
library(tidyr)
library(dplyr)
library(grid)
library(jpeg)
library(rjson)
library(RCurl)
library(densityvis)
```

#K-Nearest Neighbors


```{r, include=FALSE}
shots<-read.csv("data.csv") #read in data
shots2<-shots %>% 
  mutate(shot_made_flag=as.numeric(shot_made_flag), 
         action_type=as.numeric(action_type), combined_shot_type=as.numeric(combined_shot_type),
         playoffs=as.numeric(playoffs), shot_type=as.numeric(shot_type),
         shot_zone_area=as.numeric(shot_zone_area), shot_zone_basic=as.numeric(shot_zone_basic),
         shot_zone_range=as.numeric(shot_zone_range), period=as.numeric(period)) #turn factors into numerics for knn
test<-subset(shots2, is.na(shot_made_flag))
train<-subset(shots2, !is.na(shot_made_flag))
```

#Data Exploration

Before creating our K-NN model, we will explore the dataset, examining potential variables to be included in our distnace measurement. The below graph has broken the basketball court into various regions, and the shot accuracy for each region is indicated by the color. The size of the points corresponds to the volume of shots in a given region.



```{r, echo=FALSE}
courtImg.URL <- "https://thedatagame.files.wordpress.com/2016/03/nba_court.jpg"
court <- rasterGrob(readJPEG(getURLContent(courtImg.URL)),
           width=unit(1,"npc"), height=unit(1,"npc"))

train2<-shots
train2<-subset(train2, center_y<350 & abs(center_x)<250) #ignore backcourt shots. they are outliers
closest<-hex_pos(train2$loc_x, train2$loc_y, 70,70) #create bins
train2$center_x=closest[,1] 
train2$center_y=closest[,2]

train3<-train2 %>%
  group_by(center_x, center_y) %>%
  summarise(makes=sum(shot_made_flag), tot=n()) %>%
  mutate(Accuracy=100*makes/tot) #get accuracy for each hexagon


ggplot(train3, aes(center_x,center_y, color=Accuracy)) + #create plot
  annotation_custom(court, -250, 250, -52, 418) +
  geom_point(aes(size=tot)) + 
  scale_color_gradient(low="blue", high="red") + 
  guides(alpha = FALSE, size = FALSE) +
  xlim(250, -250) +
  ylim(-52, 418) +
  xlab("") + ylab("") + ggtitle("Kobe Bryant Shot Accuracy")
```



Notice in the above plot that the largest point is by far the one directly underneath the basket. Kobe Bryant made a career out of getting to the basket, and when he got there, he rarely missed. As expected, the points tend to turn blue and dark purple the further from the basket we move. Bryant's efficiency, as expected decreased, in general, as he move towards the three point arc and beyond. Outside the point closest to the hoop, Bryant's high volume regions tend to be on the wings, both in the mid range and at the three point arc. It is clear that both location and distance play a role in the likelihood a shot is made. Having said that, obviously the two variables are not completely independent of one another, so the inclusion of both might be unneccesary and potentially detrimental to the performance of the model.


Various categorical variables in this dataset are simply imprecise versions of distance. The categorical variable "combined_shot_type" has levels like "Jump Shot", "Dunk", and "Layup"; naturally, jump shots will be further from the basket than layups and dunks. If we know distance, then we likely know shot type as well. Furthermore, creating a distance metric for categorical variables is difficult when the categorical variables are not ordinal. While it is possible to create a numerical value for each categorical variable, doing so would at a degree of variability and subjectivity to the model that is unneccessary. Given that "combined_shot_type" and other categorical variables can be accounted for with distance and the raw x and y coordinates of each shot, we have elected not to create any distane metrics for the categorical variables. 

```{r}
by_season<-train2 %>%
  group_by(season) %>%
  summarise(fg_pct=mean(shot_made_flag), count=n())

ggplot(by_season, aes(season, fg_pct)) + geom_bar

playoffs<-train2 %>%
  group_by(playoffs) %>%
  summarise(fg_pct=mean(shot_made_flag), count=n())
colnames(playoffs)<-c("Playoffs", "FG Percentage", "Shots")

knitr::kable(playoffs)
```

Kobe Bryant is certainly known for his playoff performances, as he had led 5 Laker teams to NBA titles. While the sample size in the playoffs is much smaller, 3724 field goal attempts in the playoffs is a sufficiently large sample size; notice there is a negligible difference in Bryant's field goal percentage in the playoffs. It likely does not help us to include this predictor in the K-NN algorithm. In order to reduce the likelihood of ties, we 


Below, we have completed a 10 fold cross validation process for $k=1,5, 10, 15, ..., 150$. 


```{r}
set.seed(3)
k_vals=rep(0,30)
k=5
for (i in 1:30){
  k_vals[i]=k
  k=k+5
}
y=train$shot_made_flag
#x=train[,c(-15, -3, -4, -12, -20, -21, -22, -23, -24, -25)]
x <- train[, c(5, 8, 10, 12, 14)] %>%
  mutate(season=strtrim(season, 4)) %>%
  mutate(season=as.numeric(season))

  
idx<-createFolds(y, k=10)
errors_for_k=rep(0, length(k_vals))
for (j in 1:length(k_vals)){
  errors<-rep(0, 10)
for (i in 1:10) {
  psuedo_train=x[ -idx[[i]] , ]
  psuedo_test=x[ idx[[i]], ]
  outcomes<-y[ -idx[[i]] ]
  pred <- class::knn(train=psuedo_train, test=psuedo_test, cl=outcomes, k=k_vals[j])
  errors[i]=round(mean(y[ idx[[i]] ] != pred),3)
}
  errors_for_k[j]=mean(errors)
}

cross<-data.frame(k=k_vals, cv_mse=errors_for_k)

#which.min(cross$cv_mse) 
```
$k=120$ yielded the lowest cross-validated MSE of .3930. Since we have a binary outcome variables, it is ideal to have an odd value for $k$, so we will use $k=121$ for our K-NN model. 

```{r}
x <- train[, c(5, 8, 10, 12, 14)] %>%
  mutate(season=strtrim(season, 4)) %>%
  mutate(season=as.numeric(season))
outcomes<-train[,c(15)]
y <- test[, c(5, 8, 10, 12, 14)] %>%
  mutate(season=strtrim(season, 4)) %>%
  mutate(season=as.numeric(season))

pred <- class::knn(train=x, test=y, cl=outcomes, k=121)
test$pred=pred
```

##Submission

```{r}
sub<-test[,c(25, 26)]
write.csv(sub, "Knn_sub.csv", row.names=FALSE)
```

