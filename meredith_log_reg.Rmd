---
title: "Final Project"
author: ""
date: ""
output: 
  html_document:
    fig_height: 3
    fig_width: 5
  pdf_document:
    fig_height: 3
    fig_width: 5
  word_document:
    fig_height: 3
    fig_width: 5
---

```{r, setup, include=FALSE}
require(mosaic)
library(tidyverse)
library(glmnet)

# Some customization.  You can alter or delete as desired (if you know what you are doing).
trellis.par.set(theme=theme.mosaic()) # change default color scheme for lattice
knitr::opts_chunk$set(
  tidy=FALSE,     # display code as typed
  size="small")   # slightly smaller font for code
```



### Load and Organization Data
```{r}
# read in the data
kobe_data <- read_csv("data.csv")

set.seed(7)
# filter out test set from the train set and convert `shot_made_flag` to a factor
train <- kobe_data %>%
  filter(!is.na(shot_made_flag)) %>%
  mutate(shot_made_flag = as.factor(shot_made_flag))

test <- kobe_data %>%
  anti_join(train, by="shot_id") %>%
  mutate(shot_made_flag = as.factor(shot_made_flag))


# create variable which denotes halves and over time for train and test set
time <- ifelse(train$period == 1,"first", 
       ifelse(train$period == 2, "first", 
              ifelse(train$period == 3, "second", 
                     ifelse(train$period == 4, "second", "OT"))))
train <- mutate(train, game_part = time)

time <- ifelse(test$period == 1,"first", 
       ifelse(test$period == 2, "first", 
              ifelse(test$period == 3, "second", 
                     ifelse(test$period == 4, "second", "OT"))))
test <- mutate(test, game_part = time)

# convert all characters to factors in train and test set
train <- train %>%
  mutate(season = as.factor(season),
         shot_type = as.factor(shot_type),
         shot_zone_area = as.factor(shot_zone_area),
         shot_zone_basic = as.factor(shot_zone_basic),
         shot_zone_range = as.factor(shot_zone_range),
         team_name = as.factor(team_name),
         matchup = as.factor(matchup),
         opponent = as.factor(opponent),
         game_part = as.factor(game_part))

test <- test %>%
  mutate(season = as.factor(season),
         shot_type = as.factor(shot_type),
         shot_zone_area = as.factor(shot_zone_area),
         shot_zone_basic = as.factor(shot_zone_basic),
         shot_zone_range = as.factor(shot_zone_range),
         team_name = as.factor(team_name),
         matchup = as.factor(matchup),
         opponent = as.factor(opponent),
         game_part = as.factor(game_part))

```


### Exploratory Analysis

#### Descriptive Statistics
```{r}
# Percentage of Shots Made
train %>%
  filter(shot_made_flag == "1") %>%
  summarise(count_made = n()/25697)
# COMMENT: 11,465 shots made out of 25,697, thus yielding a 0.446161 field goal percentge
# for his career based on this data

# Percentage of Shots Missed
train %>%
  filter(shot_made_flag == "0") %>%
  summarise(count_missed = n()/25697)
# COMMENT: Bryant missed 0.553839 of his shots throughout his career based on this data




# Percentage of Shots Made Grouped by `shot_type`
train %>%
  group_by(shot_type) %>%
  filter(shot_made_flag == "1") %>%
  summarise(count_made = n()/25697)
# COMMENT: 0.37681441 of all of his shots were successful 2PT field goals and 0.06934662 
# of all of his shots were successful 3PT field goals.




# Percentage of Shots Made Grouped by `action_type`
train %>%
  group_by(action_type) %>%
  filter(shot_made_flag == "1") %>%
  summarise(count_made = n()/25697) %>%
  arrange(desc(count_made))
# COMMENT: of all the shots that he took, 20% of the shots were successful jump shots 
# i.e. gained points from this shot

train %>%
  filter(action_type == "Jump Shot") %>%
  summarise(count_JS = n(), count_PJS = n()/25697)
# COMMENT: of all the shots he took 15,836 or 0.6162587 were jump shots

train %>%
  group_by(action_type) %>%
  filter(shot_made_flag == "1") %>%
  summarise(count_made = n()/11465) %>%
  arrange(desc(count_made))
# COMMENT: Of all the shots that Bryant made, 0.45154819 were jump shots, proving to
# be the action with the highest percentage, followed by driving layup shots and layup
# shots recorded at 0.1053 and 0.0724 respectively.


# Comparing some totals to stats from 
# "https://www.basketball-reference.com/players/b/bryanko01.html#all_totals" to make sure 
# we stay close to what is true
```


#### Visualizations
```{r}
train %>%
  filter(loc_y >= 300) %>%
  group_by(shot_made_flag) %>%
  summarise(count = n())
# COMMENT: of the 142 shots he took beyond loc_y = 300 he only made 6, so the shots at
# this distance are very low percentage
  
plot <- ggplot(train, aes(x=loc_x, y=loc_y, col = shot_made_flag)) + geom_point()
plot

train %>%
  filter(shot_made_flag == 1, loc_y >=400)
# COMMENT: this plot illustrated the previous point. The location of his furthest 
# successful shot was from beyond loc_y = 400, which was scored from 43ft from
# the basket, i.e. the back court, in a regular 2001-2002 season game in the second period
# against the Utah Jazz.

viz <- train %>%
  filter(shot_made_flag == "1")

plot1 <- ggplot(viz, aes(x=loc_x, y=loc_y, col = as.factor(shot_type))) + geom_point()
plot1
# why is there a clear space between the 2PT shots and the 3PT shots? 
# add a three point arch?
check <- train %>%
  filter(shot_distance >= 22, shot_distance <= 23.75)

# Shots Made Broken up by First half, Second Half, and Over-Time
plot2 <- ggplot(train, aes(x=loc_x, y=loc_y, 
          col = shot_made_flag, shape = shot_made_flag, size = shot_made_flag)) +
  geom_point() +
  facet_wrap(~game_part)
plot2
# COMMENT: as we can see from the plot, Byrant is fairly consist with the shots that with
# the shots that he makes, but as the game goes on he becomes more conservative with his
# shot selection
```


### Modeling using LASSO

#### Necessary Functions for Procedure
```{r}
# Wrapper Function
get_LASSO_coefficients <- function(LASSO_fit){
  coeff_values <- LASSO_fit %>% 
    broom::tidy() %>% 
    as_tibble() %>% 
    select(-c(step, dev.ratio)) %>% 
    tidyr::complete(lambda, nesting(term), fill = list(estimate = 0)) %>% 
    arrange(desc(lambda)) %>% 
    select(term, estimate, lambda)
  return(coeff_values)
}

# Log-Loss function
 LogLossBinary = function(actual, predicted, eps = 1e-15) {
  predicted = pmin(pmax(predicted, eps), 1-eps)
  - (sum(actual * log(predicted) + (1 - actual) * log(1 - predicted))) / length(actual)
} #https://www.r-bloggers.com/making-sense-of-logarithmic-loss/
```

We will use the wrapper function when we look at plots of the coefficients and we will use the Log-Loss function when determing how our model performed on the training set to give us a gauge before we submit our results to kaggle.com.

#### Define the Model
```{r} 
model_formula <- as.formula(shot_made_flag ~ combined_shot_type + lat + loc_x + loc_y + lon + minutes_remaining + period + playoffs + season + shot_distance + shot_type + matchup + opponent)
```

The initial model will include all provided variables. However,`team_name` or `team_id` will not be included in the model because he spent his entire career playing for the Los Angeles Lakers. That being said both of these variables only have one level which produces an error when creating the predictor matrix. Additionally, `game_part` was a variable only created for exploratory analysis, so we do not want to include it as it summarizes information from `period` and thus its contribution is redundant. Below we create the predictor matrices for the train and the test set. Lastly, because `action_type` is moderately associated with `shot_distance`, we will not include this variable in the model. Did not include `seconds_remaining` because most of that information is captured in `minutes_remaining`. Similarly we did not include `shot_zone_area`, `shot_zone_basic` and `shot_zone_basic` as this information is captured in `shot_distance`.


#### Predictor Matrices
```{r}
# Predictor Matrix for Training Set
predictor_matrix_train <- model.matrix(model_formula, data = train)[, -1]

# dummy filler so that we can create the test predictor matrix
test$shot_made_flag <- rep(c(1,0)) 

# Predictor Matrix for the Test Set
predictor_matrix_test <- model.matrix(model_formula, data = test)[,-1]
```

It is important to note that in the test set `shot_made_flag` only had one level because it was a vector of all NA's since this information was not provided and is what we are trying to predict. With that being said we ran into a similar error for the test set's `shot_made_flag` as we did for `team_name` and `team_id`, so we assigned alternating 1's and 0's to this data so that we can run the predictor matrix, but the prector matrix does not include `shot_made_flag`, so ultimately this does not create an issue for the rest of the process.


#### First Attempt to Fit Model
```{r}
# Define values of tuning/complexity parameter lambda
lambda_inputs <- 10^seq(-2, 0, length = 100)
# range of lambda values, we go from 10^-2 and 10^0 now insteand of an upper bound of
# 10^10

# Fitting the Model
LASSO_fit <- glmnet(x=predictor_matrix_train, y=train$shot_made_flag, alpha = 1, 
                    lambda = lambda_inputs, family = "binomial") 
# use family = "binomial" for logistic regression

# Get beta-hat coefficients for ALL values of knob/tuning parameter lambda
LASSO_coefficients <- get_LASSO_coefficients(LASSO_fit)

# Coefficient Analysis Plot
plot_LASSO_coefficients <- LASSO_coefficients %>% 
  filter(term != "(Intercept)") %>% 
  ggplot(aes(x=lambda, y=estimate, col=term)) +
  geom_line() +
  scale_x_log10() +
  labs(x="lambda (log10-scale)", y="beta-hat coefficient estimate",
       title="LASSO regularized coefficient for each lambda value") 

```

We set the values for lambda and proceed to fit an initial model based on this tuning parameter. In the plot the x-axis is on a log10 scale so that we can more easily see the values of lambda on the x-axis. The plot above illustrates each setting of lambda on the x-axis log10 scale with the beta_hat coefficient estimate on the y-axis. We are most interested with where the beta_hats equal zero. The coefficients which last drop to zero will contribute most to the model. Before we look further into these variables we will use crossvalidation to further improve our model.

#### Fitting the Model with Crossvalidation
```{r}
# Model fit with crossvalidation
LASSO_CV <- cv.glmnet(x=predictor_matrix_train, y=train$shot_made_flag, alpha=1, lambda=lambda_inputs, family = "binomial") # takes a little bit to run
# crossvalidation to find the optimal value λ_star of λ that yields the β_hat’s for the predictive model that in turn yields the lowest MSE


# Optimal lambdas
lambda_star <- LASSO_CV$lambda.min
lambda_star_1SE <- LASSO_CV$lambda.1se

plot(LASSO_CV)
abline(v=log(lambda_star), col="red")
abline(v=log(lambda_star_1SE), col="blue")

# the blue line indicates the number of nonzero beta_hats associated with 1SE of the lowest MSE
# 4 coefficients

plot_LASSO_coefficients <- plot_LASSO_coefficients +
  geom_vline(xintercept = lambda_star, col="red", alpha=0.4, linetype="dashed") +
  geom_vline(xintercept = lambda_star_1SE, col="blue", alpha=0.4, linetype="dashed")
plot_LASSO_coefficients

# want to be able to zoom in, but can't see xlim <1
plot_LASSO_coefficients +
  coord_cartesian(ylim=c(-0.5, 0.5))
```

We use cross validation to obtain the lambda_star for lambda which yield beta_hat's associated with the lowest MSE values. However in an effort to preserve model simplicity we will want to use the beta_hat's associated with MSE values which are at most one standard error away from the minimum MSE. Based on the plot above we can see that all variables contribute to the model so we will use all variables when prediction shot selection in the test set. The variables that contribute most significantly to this model are as follows in order of most informative to least informative:
*`combined_shot_type Dunk`
*`combined_shot_type Jump Shot`
*`shot_distance`
*`shot_type 3PT Field Goal`

#### Score the Model
```{r}
# predicted values from the 5000 observations training set
log_odds_hat <- predict(LASSO_CV, newx=predictor_matrix_train, s=lambda_star_1SE) %>% 
  as.vector()
hist(log_odds_hat)

p_hat <- 1/(1 + exp(-log_odds_hat))
hist(p_hat)
# p_hat's only range from zero to one, so as far as we know we have correctly calculated the probabilities

# sanity check
plot(p_hat, train$shot_distance)
# this confirms that our probabilities are on the right track because `shot_distance` and the probability
# of the shot are negatively assiciated, i.e. as `shot_distance` goes up, `p_hat` goes down.

train <- mutate(train, p_hat = p_hat)

# establish cutoff - 50/50
shot_made_flag_hat <- ifelse(train$p_hat < .5, 0, 1)
train <- mutate(train, shot_made_flag_hat = shot_made_flag_hat)

# Log-loss for predicted on train
train$shot_made_flag <- as.numeric(train$shot_made_flag)
train$shot_made_flag <- ifelse(train$shot_made_flag == 1, 0, 1)
LogLossBinary(train$shot_made_flag, train$p_hat)


### Compare Log-Loss for LASSO_fit v Log-Loss for LASSO_CV -- the latter should have 
# a better score because we have chosen the optimal lambda
```

The Log-Loss value for the training set is 0.6546459. We will use this as a point of comparison when we obtain the score from kaggle.com.

#### Make Predictions on Test Set
```{r}
# predicted values from test
log_odds_hat <- predict(LASSO_CV, newx=predictor_matrix_test, s=lambda_star_1SE) %>% 
  as.vector()
hist(log_odds_hat)

p_hat <- 1/(1 + exp(-log_odds_hat))
hist(p_hat)
# p_hat's only range from zero to one, so as far as we know we have correctly calculated the probabilities

# sanity check
plot(p_hat, test$shot_distance)
# this confirms that our probabilities are on the right track because `shot_distance` and the probability
# of the shot are negatively assiciated, i.e. as `shot_distance` goes up, `p_hat` goes down.

test <- mutate(test, p_hat = p_hat)

# establish cutoff
shot_made_flag <- ifelse(test$p_hat < .5, 0, 1)
test <- mutate(test, shot_made_flag = shot_made_flag)

# create submission file
submission <- test[c(25, 15)]
write.csv(submission, "LASSO_submission.csv")
```



Kaggle submission score: 17.35250 - need to work on this   
